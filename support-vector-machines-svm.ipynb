{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-09T10:37:48.356325Z","iopub.execute_input":"2026-01-09T10:37:48.356684Z","iopub.status.idle":"2026-01-09T10:37:48.363036Z","shell.execute_reply.started":"2026-01-09T10:37:48.356660Z","shell.execute_reply":"2026-01-09T10:37:48.361735Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 1. Core Idea\n\nSupport Vector Machines (SVM) is a supervised learning algorithm used for **classification and regression**.\nUnlike many algorithms that look for any separating boundary, SVM finds the **optimal boundary** that separates classes with the **maximum margin**.\n\nThe **margin** is the distance between the decision boundary and the closest data points from each class.\nThese closest points are called **support vectors**. They fully determine the position of the boundary.\n\n---\n\n### 2. Hard Margin vs Soft Margin\n\nReal-world data is rarely perfectly separable, so SVM allows two formulations:\n\n**Hard Margin**\n\n* Assumes perfect separation.\n* No points are allowed inside the margin or on the wrong side.\n* Very sensitive to noise.\n\n**Soft Margin**\n\n* Allows some misclassification and margin violations.\n* More robust and widely used.\n\nThe trade-off is controlled by the **C parameter**:\n\n* **High C**\n  The model strongly penalizes errors. It tries to classify every point correctly, which can lead to overfitting.\n\n* **Low C**\n  The model allows more misclassification but keeps a wider margin, improving generalization.\n\n---\n\n### 3. The Kernel Trick\n\nMany datasets are not linearly separable in their original feature space.\nSVM solves this by mapping data into a **higher-dimensional space** where separation becomes easier.\n\nInstead of explicitly creating new features, SVM uses the **kernel trick**, which computes inner products in high-dimensional space efficiently without performing the actual transformation. This makes nonlinear classification practical.\n\n---\n\n### 4. Common Kernels\n\nDifferent kernels model different data patterns:\n\n* **Linear Kernel**\n  Best when the data is approximately linearly separable.\n\n* **Polynomial Kernel**\n  Useful for data with curved boundaries.\n\n* **RBF (Radial Basis Function)**\n  The most commonly used nonlinear kernel. It creates flexible decision boundaries by giving higher influence to nearby points.\n\n---\n\n### 5. Advantages and Limitations\n\n**Advantages**\n\n* Works well in high-dimensional feature spaces.\n* Effective for complex nonlinear relationships using kernels.\n* Depends only on support vectors, making it robust to many irrelevant points.\n\n**Limitations**\n\n* Computationally expensive for large datasets.\n* Sensitive to noise when C is too high.\n* Requires careful tuning of hyperparameters (C, kernel, gamma).\n\n---\n\n### Summary\n\nSVM is a powerful algorithm for **small to medium-sized datasets with complex boundaries**. With the right kernel and parameter tuning, it can achieve very high performance, but it is not suitable for very large Kaggle datasets due to its computational cost.\n\n---\n\n","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom scipy import stats\n\n# use seaborn plotting defaults\nimport seaborn as sns; sns.set()\nfrom matplotlib.axes._axes import _log as matplotlib_axes_logger\nfrom mpl_toolkits import mplot3d\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom matplotlib.colors import ListedColormap","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T10:37:48.364439Z","iopub.execute_input":"2026-01-09T10:37:48.364804Z","iopub.status.idle":"2026-01-09T10:37:48.381383Z","shell.execute_reply.started":"2026-01-09T10:37:48.364781Z","shell.execute_reply":"2026-01-09T10:37:48.380257Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.datasets import make_blobs\nX,y = make_blobs(n_samples=50,centers=2,\n                random_state=0,cluster_std=0.60)\nplt.scatter(X[:,0],X[:,1],c=y,s=50,cmap='winter')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T10:37:48.382769Z","iopub.execute_input":"2026-01-09T10:37:48.383124Z","iopub.status.idle":"2026-01-09T10:37:48.660913Z","shell.execute_reply.started":"2026-01-09T10:37:48.383063Z","shell.execute_reply":"2026-01-09T10:37:48.660034Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = SVC(kernel='linear',C=1)\nmodel.fit(X,y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T10:37:48.661811Z","iopub.execute_input":"2026-01-09T10:37:48.662109Z","iopub.status.idle":"2026-01-09T10:37:48.671159Z","shell.execute_reply.started":"2026-01-09T10:37:48.662071Z","shell.execute_reply":"2026-01-09T10:37:48.670109Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_svc_decision_function(model, ax=None, plot_support=True):\n    \"\"\"Plot the decision function for a 2D SVC\"\"\"\n    if ax is None:\n        ax = plt.gca()\n    xlim = ax.get_xlim()\n    ylim = ax.get_ylim()\n    \n    # create grid to evaluate model\n    x = np.linspace(xlim[0], xlim[1], 30)\n    y = np.linspace(ylim[0], ylim[1], 30)\n    Y, X = np.meshgrid(y, x)\n    xy = np.vstack([X.ravel(), Y.ravel()]).T\n    P = model.decision_function(xy).reshape(X.shape)\n    \n    # plot decision boundary and margins\n    ax.contour(X, Y, P, colors='k',\n               levels=[-1, 0, 1], alpha=0.5,\n               linestyles=['--', '-', '--'])\n    \n    # plot support vectors\n    if plot_support:\n        ax.scatter(model.support_vectors_[:, 0],\n                   model.support_vectors_[:, 1],\n                   s=300, linewidth=1, facecolors='none');\n    ax.set_xlim(xlim)\n    ax.set_ylim(ylim)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T10:37:48.673336Z","iopub.execute_input":"2026-01-09T10:37:48.674006Z","iopub.status.idle":"2026-01-09T10:37:48.687022Z","shell.execute_reply.started":"2026-01-09T10:37:48.673980Z","shell.execute_reply":"2026-01-09T10:37:48.685884Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='winter')\nplot_svc_decision_function(model);","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T10:37:48.688137Z","iopub.execute_input":"2026-01-09T10:37:48.688610Z","iopub.status.idle":"2026-01-09T10:37:48.951017Z","shell.execute_reply.started":"2026-01-09T10:37:48.688577Z","shell.execute_reply":"2026-01-09T10:37:48.950278Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_svm(N=10, ax=None):\n    X, y = make_blobs(n_samples=200, centers=2,\n                      random_state=0, cluster_std=0.60)\n    X = X[:N]\n    y = y[:N]\n    model = SVC(kernel='linear', C=1E10)\n    model.fit(X, y)\n    \n    ax = ax or plt.gca()\n    ax.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='winter')\n    ax.set_xlim(-1, 4)\n    ax.set_ylim(-1, 6)\n    plot_svc_decision_function(model, ax)\n\nfig, ax = plt.subplots(1, 2, figsize=(16, 6))\nfig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\nfor axi, N in zip(ax, [60, 120]):\n    plot_svm(N, axi)\n    axi.set_title('N = {0}'.format(N))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T10:37:48.952008Z","iopub.execute_input":"2026-01-09T10:37:48.952342Z","iopub.status.idle":"2026-01-09T10:37:49.498722Z","shell.execute_reply.started":"2026-01-09T10:37:48.952312Z","shell.execute_reply":"2026-01-09T10:37:49.497633Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\nWorking with Almost Linearly Separable Dataset","metadata":{}},{"cell_type":"code","source":"X, y = make_blobs(n_samples=100, centers=2,\n                  random_state=0, cluster_std=1.2)\nplt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='winter');","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T10:37:49.499663Z","iopub.execute_input":"2026-01-09T10:37:49.499987Z","iopub.status.idle":"2026-01-09T10:37:49.757005Z","shell.execute_reply.started":"2026-01-09T10:37:49.499967Z","shell.execute_reply":"2026-01-09T10:37:49.755905Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X, y = make_blobs(n_samples=100, centers=2,\n                  random_state=0, cluster_std=0.8)\n\nfig, ax = plt.subplots(1, 2, figsize=(16, 6))\nfig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\n\nfor axi, C in zip(ax, [100.0, 0.01]):\n    model = SVC(kernel='linear', C=C).fit(X, y)\n    axi.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='winter')\n    plot_svc_decision_function(model, axi)\n    axi.scatter(model.support_vectors_[:, 0],\n                model.support_vectors_[:, 1],\n                s=300, lw=1, facecolors='none');\n    axi.set_title('C = {0:.1f}'.format(C), size=14)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T10:37:49.757987Z","iopub.execute_input":"2026-01-09T10:37:49.758340Z","iopub.status.idle":"2026-01-09T10:37:50.368201Z","shell.execute_reply.started":"2026-01-09T10:37:49.758319Z","shell.execute_reply":"2026-01-09T10:37:50.367167Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.datasets import make_circles\nX, y = make_circles(100, factor=.1, noise=.1)\n\nplt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='bwr')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T10:37:50.369290Z","iopub.execute_input":"2026-01-09T10:37:50.369607Z","iopub.status.idle":"2026-01-09T10:37:50.586018Z","shell.execute_reply.started":"2026-01-09T10:37:50.369581Z","shell.execute_reply":"2026-01-09T10:37:50.584944Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T10:37:50.588595Z","iopub.execute_input":"2026-01-09T10:37:50.588828Z","iopub.status.idle":"2026-01-09T10:37:50.593646Z","shell.execute_reply.started":"2026-01-09T10:37:50.588811Z","shell.execute_reply":"2026-01-09T10:37:50.592678Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"classifier = SVC(kernel=\"linear\")\nclassifier.fit(X_train, y_train.ravel())\ny_pred = classifier.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T10:37:50.594629Z","iopub.execute_input":"2026-01-09T10:37:50.595511Z","iopub.status.idle":"2026-01-09T10:37:50.610456Z","shell.execute_reply.started":"2026-01-09T10:37:50.595487Z","shell.execute_reply":"2026-01-09T10:37:50.609537Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test, y_pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T10:37:50.611393Z","iopub.execute_input":"2026-01-09T10:37:50.611701Z","iopub.status.idle":"2026-01-09T10:37:50.624628Z","shell.execute_reply.started":"2026-01-09T10:37:50.611682Z","shell.execute_reply":"2026-01-09T10:37:50.623892Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"zero_one_colourmap = ListedColormap(('blue', 'red'))\ndef plot_decision_boundary(X, y, clf):\n    X_set, y_set = X, y\n    X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, \n                                 stop = X_set[:, 0].max() + 1, \n                                 step = 0.01),\n                       np.arange(start = X_set[:, 1].min() - 1, \n                                 stop = X_set[:, 1].max() + 1, \n                                 step = 0.01))\n  \n    plt.contourf(X1, X2, clf.predict(np.array([X1.ravel(), \n                                             X2.ravel()]).T).reshape(X1.shape),\n               alpha = 0.75, \n               cmap = zero_one_colourmap)\n    plt.xlim(X1.min(), X1.max())\n    plt.ylim(X2.min(), X2.max())\n    for i, j in enumerate(np.unique(y_set)):\n        plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = (zero_one_colourmap)(i), label = j)\n    plt.title('SVM Decision Boundary')\n    plt.xlabel('X1')\n    plt.ylabel('X2')\n    plt.legend()\n    return plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T10:37:50.625556Z","iopub.execute_input":"2026-01-09T10:37:50.626256Z","iopub.status.idle":"2026-01-09T10:37:50.641247Z","shell.execute_reply.started":"2026-01-09T10:37:50.626224Z","shell.execute_reply":"2026-01-09T10:37:50.640342Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_decision_boundary(X, y, classifier)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T10:37:50.642220Z","iopub.execute_input":"2026-01-09T10:37:50.642844Z","iopub.status.idle":"2026-01-09T10:37:51.383566Z","shell.execute_reply.started":"2026-01-09T10:37:50.642816Z","shell.execute_reply":"2026-01-09T10:37:51.382499Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_3d_plot(X, y):\n    r = np.exp(-(X ** 2).sum(1))\n    ax = plt.subplot(projection='3d')\n    ax.scatter3D(X[:, 0], X[:, 1], r, c=y, s=100, cmap='bwr')\n    ax.set_xlabel('X1')\n    ax.set_ylabel('X2')\n    ax.set_zlabel('y')\n    return ax","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T10:38:27.503680Z","iopub.execute_input":"2026-01-09T10:38:27.504639Z","iopub.status.idle":"2026-01-09T10:38:27.510012Z","shell.execute_reply.started":"2026-01-09T10:38:27.504609Z","shell.execute_reply":"2026-01-09T10:38:27.509031Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_3d_plot(X,y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T10:38:38.718779Z","iopub.execute_input":"2026-01-09T10:38:38.719520Z","iopub.status.idle":"2026-01-09T10:38:38.910661Z","shell.execute_reply.started":"2026-01-09T10:38:38.719493Z","shell.execute_reply":"2026-01-09T10:38:38.909859Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nrbf_classifier = SVC(kernel=\"rbf\")\nrbf_classifier.fit(X_train, y_train)\ny_pred = rbf_classifier.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T10:39:00.428371Z","iopub.execute_input":"2026-01-09T10:39:00.429243Z","iopub.status.idle":"2026-01-09T10:39:00.436887Z","shell.execute_reply.started":"2026-01-09T10:39:00.429216Z","shell.execute_reply":"2026-01-09T10:39:00.435912Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"accuracy_score(y_test, y_pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T10:39:12.459772Z","iopub.execute_input":"2026-01-09T10:39:12.460974Z","iopub.status.idle":"2026-01-09T10:39:12.467965Z","shell.execute_reply.started":"2026-01-09T10:39:12.460943Z","shell.execute_reply":"2026-01-09T10:39:12.467279Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_decision_boundary(X, y, rbf_classifier)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T10:39:22.170886Z","iopub.execute_input":"2026-01-09T10:39:22.171640Z","iopub.status.idle":"2026-01-09T10:39:22.609957Z","shell.execute_reply.started":"2026-01-09T10:39:22.171612Z","shell.execute_reply":"2026-01-09T10:39:22.609067Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"poly_classifier = SVC(kernel=\"poly\",degree=2)\npoly_classifier.fit(X_train, y_train)\ny_pred = poly_classifier.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T10:39:50.213544Z","iopub.execute_input":"2026-01-09T10:39:50.214344Z","iopub.status.idle":"2026-01-09T10:39:50.221246Z","shell.execute_reply.started":"2026-01-09T10:39:50.214313Z","shell.execute_reply":"2026-01-09T10:39:50.220185Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"accuracy_score(y_test, y_pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T10:40:25.417474Z","iopub.execute_input":"2026-01-09T10:40:25.418324Z","iopub.status.idle":"2026-01-09T10:40:25.424839Z","shell.execute_reply.started":"2026-01-09T10:40:25.418296Z","shell.execute_reply":"2026-01-09T10:40:25.424152Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_decision_boundary(X, y, poly_classifier)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T10:40:29.215224Z","iopub.execute_input":"2026-01-09T10:40:29.215562Z","iopub.status.idle":"2026-01-09T10:40:29.595457Z","shell.execute_reply.started":"2026-01-09T10:40:29.215538Z","shell.execute_reply":"2026-01-09T10:40:29.594502Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}